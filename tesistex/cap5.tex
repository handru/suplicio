\label{pagcap5}
\chapter{Conclusiones y Trabajos Futuros}

En este cap\'itulo se presentan las principales conclusiones de esta tesis. En la \'ultima secci\'on se presentan las potenciales l\'ineas futuras de acci\'on que puedan complementar el trabajo desarrollado.


\section{Conclusiones}
La paralelizaci\'on de una aplicaci\'on legacy es una tarea compleja con muchos aspectos. Se realiza en varias etapas incrementales que van impactando en mayor o menor medida en los resultados. La finalidad de la paralelizaci\'on puede ser buscar mejorar la performance, la utilizaci\'on de recursos, la calidad de los resultados, etc. El presente trabajo se enfoc\'o en la mejora de utilizaci\'on de recursos, en la etapa de optimizaci\'on serial, y de la performance, en la etapa de optimizaci\'on paralela. Sin embargo, en ambas etapas se obtuvieron mejoras parciales en ambos aspectos.

Para poder realizar el trabajo de tesis fue necesario estudiar y aprender el lenguaje Fortran; luego, estudiar el c\'odigo de la aplicaci\'on objeto de estudio para comprender su forma de trabajar, y luego poder realizar los cambios necesarios sin modificar substancialmente el c\'odigo. Recorriendo este camino se adquirieron conocimientos sobre el est\'andar OpenMP y sobre la optimizaci\'on de aplicaciones para Computaci\'on de Altas Prestaciones.

Para poder enfrentar el trabajo de optimizaci\'on adecuadamente fue necesario un an\'alisis de la aplicaci\'on bajo estudio. Tomamos el programa original, ejecut\'andolo con un tama\~no del problema de 50x50, para obtener mediciones que dieran la base de comparaci\'on para las etapas de optimizaci\'on. Luego se aplic\'o la optimizaci\'on tal como se describi\'o en el cap\'itulo 3: optimizaci\'on del c\'odigo serial en primer lugar, y paralelizaci\'on de una porci\'on del c\'odigo posteriormente. Esta paralelizaci\'on se realiz\'o aplicando las directivas de OpenMP a la subrutina estela.

Luego de la primera etapa, de optimizaci\'on serial, se logr\'o una mejora en el tiempo de ejecuci\'on, aunque todav\'ia reducida (factor de mejora o speedup de 1.34). Al realizar la optimizaci\'on paralela obtuvimos un mayor speedup (con valores de 3.58 en un equipo de pruebas y 2.59 en otro). Estos factores de mejora estaban m\'as de acuerdo con la intuici\'on, ya que la optimizaci\'on afectaba a una subrutina que consum\'ia entre un 74\% y un 79\% del tiempo de ejecuci\'on original.

Al ocuparnos del uso de discos y memoria, trasladamos los archivos desde el filesystem, residente en disco, a la memoria RAM para un acceso mas r\'apido. Sin embargo esta modificaci\'on no tuvo un impacto tan notable como se esperaba. Se duplic\'o aproximadamente la utilizaci\'on de memoria RAM, sin que esto representara un inconveniente dados los equipos utilizados. En equipos con 1 GB de RAM (en la actualidad es habitual contar con 2 GB o m\'as) el programa seguir\'ia teniendo memoria suficiente para ejecutarse usando el tama\~no de problema de 50x50. %OSO para qu\'e tama\~nos de problema?

%OSO en el p\'arrafo que sigue, las pruebas con tama\~no de problema mayor, son despues de todo el proceso de optimizaci\'on?
Por \'ultimo, sobre uno de los equipos se llevaron a cabo pruebas con un tama\~no de problema mayor (80x80), sobre la versi\'on original, optimizada serialmente y optimizada paralelamente. Primero se realiz\'o un perfilado, donde se pudo observar que los porcentajes de tiempo de las subrutinas estela y solgauss casi se hab\'ian equiparado (46\% y 43\% respectivamente). En las pruebas esto mostr\'o que la mejora de tiempo al paralelizar no fue tan grande como con el tama\~no de problema menor, lo cual lleva a la necesidad de paralelizar solgauss para poder obtener mayor mejora en tama\~nos m\'as grandes de problema para la aplicaci\'on. Tambi\'en podemos concluir que claramente el incremento de tama\~no del problema y la optimizaci\'on impactan en la memoria del sistema y debe tenerse en cuenta la cantidad de RAM disponible si el usuario quisiera incrementar a\'un m\'as el tama\~no del problema.

\section{Trabajos Futuros}
En funci\'on del trabajo de tesis se identificaron algunos aspectos que permitir\'ian extender el trabajo realizado. Estos aspectos se detallan a continuaci\'on:
\begin{itemize}
\item Analizar si al aumentar a\'un mas el tama\~no del problema, con perfilado de la aplicaci\'on original, siguen invirti\'endose los tiempos de las subrutinas, y ver si es necesario optimizar de otra manera. Tambi\'en utilizar herramientas de perfilado de aplicaciones paralelas con OpenMP, como ``ompp''.
\item Otra l\'inea de trabajo podr\'ia ser proponer una recodificaci\'on de la aplicaci\'on para aprovechar mejoras en el lenguaje Fortran y otras bibliotecas existentes para la realizaci\'on de los c\'alculos.
\item Se podr\'ia paralelizar la subrutina solgauss y analizar si es necesario recodificar la subrutina o si se puede optimizar en su estado original. Adem\'as analizar si la ganancia en performance en el tama\~no de problema menor es o no despreciable; y, en problemas de mayor tama\~no, qu\'e speedup puede obtenerse.
\item Realizar la optimizaci\'on utilizando conjuntamente OpenMP y la API MPI, y analizar la posibilidad de utilizar un cluster para la ejecuci\'on de la aplicaci\'on aprovechando la capacidad de c\'omputo de varios nodos.
\item Investigar c\'omo una implementaci\'on del est\'andar OpenMP difiere de otras y qu\'e problemas se presentan, teniendo en cuenta el problema visto en el cap 3 con la inicializaci\'on en cero de arrays utilizando OpenMP.

\end{itemize}