\label{pagcap5}
\chapter{Conclusiones y Trabajos Futuros}

En este capítulo se presentan las principales conclusiones de esta tesis. En la última sección se presentan las potenciales líneas futuras de acción que puedan complementar el trabajo desarrollado.


\section{Conclusiones}
La paralelización de una aplicación heredada es una tarea compleja con muchos aspectos. Se realiza en varias etapas incrementales que van impactando en mayor o menor medida en los resultados. La finalidad de la paralelización puede ser buscar mejorar el rendimiento, la utilización de recursos, la calidad de los resultados, etc. El presente trabajo tomó una aplicación heredada del campo de la Dinámica de Fluidos, y se enfocó en la mejora de rendimiento (\emph{speed-up}) de la aplicación a través de paralelizar porciones de código de la misma que fueran muy costosas en tiempo. Esto implicó llevar adelante un proceso de optimización, donde en su etapa intermedia, optimización del código serie, también se tomaron mediciones de la mejora en el rendimiento de la aplicación. Conjuntamente se tomaron datos sobre la utilización de recursos de la misma, observando la utilización de disco y memoria RAM.

Para poder llevar adelante el trabajo de optimización paralela se realizó un análisis de la aplicación bajo estudio y se tomó un proceso de optimización en dos etapas bien definidas, una optimización serial (sin paralelizar) del código y luego una optimización paralela. Se hizo un perfilado de la aplicación con la herramienta \emph{gprof}, para encontrar las subrutinas candidatas a ser optimizadas paralelamente, seleccionando las que mas tiempo de computación consumen durante la ejecución. Como la aplicación se puede ejecutar con un tamaño de problema variable y los datos de prueba facilitados por el creador de la aplicación eran para tamaños de problema de \textsc{T50x50} paneles y \textsc{T80x80} paneles, se realizó un perfilado para la aplicación utilizando ambos tamaños, y se observó que hay diferencias en los resultados de acuerdo al tamaño del problema, observando que al crecer el tamaño del problema, crece también el tiempo utilizado en una subrutina en particular, \emph{solgauss}.

Tomando el equipo PC2 donde se probó con ambos tamaños, en el resultado del perfilado para el tamaño del problema menor se observó que \emph{estela} se ejecuta 76,21\% del tiempo y \emph{solgauss} lo hace un 15,96\%, y para el tamaño mayor los tiempos fueron 46,42\% para \emph{estela} y 43,09\% para \emph{solgauss}. De estos resultados se decidió que la subrutina \emph{estela} representaba la principal candidata a ser optimizada paralelamente, teniendo en cuenta que al aumentar el tamaño del problema, seguramente es necesario que sea paralelizada la subrutina \emph{solgauss} para mejorar el rendimiento, algo que se observó al tomar las mediciones.

Al analizar el código y la aplicación en ejecución, se observó que la misma utiliza disco para guardar los cálculos que realiza, generando gran cantidad de archivos (58) que son leídos y escritos a lo largo de la ejecución. Teniendo en cuenta que los tiempos de acceso a disco son lentos en comparación con el acceso a memoria RAM, se decidió enfocar la etapa de optimización serial en que todo calculo escrito y leído desde disco sea alojado en memoria RAM, demorando la escritura en disco de resultados hasta el final de la ejecución de la aplicación o de una subrutina en particular, sin modificar la cantidad de archivos generados, excepto por los archivos con extensión ``.tmp'' los cuales eran binarios y no eran necesarios luego de la ejecución.

Finalmente en la etapa de optimización paralela se aplicó OpenMP en la subrutina \emph{estela} para paralelizar el bucle principal de calculo del código de la misma, donde se analizó específicamente que datos se deben enviar dentro de la región paralela de OpenMP sin modificar, inicializados o no, y si la región debe tener puntos de control o no para forzar la sincronización. 

En el Capítulo 4 se han observado las mediciones tomadas de las distintas versiones de la aplicación con los distintos tamaños de problema en los equipos seleccionados. Las versiones son la aplicación original sin modificar, la versión optimizada serial y la versión optimizada paralela.

Lo primero que se realizó fue ejecutar la aplicación original en cada equipo, de esta manera obtuvimos mediciones que dieran la base de comparación para las etapas de optimización. Luego se tomaron mediciones de cada versión en cada tamaño de problema.
Luego de la primera etapa de optimización serial, se logró una mejora en el tiempo de ejecución en un factor de 1.35 en \textsc{PC1} y de 1.34 en \textsc{PC2} para el tamaño \textsc{T50x50}. Al realizar la optimización paralela se obtuvo un mayor factor de rendimiento con valores de 3.58 en \textsc{PC1} y 2.59 en \textsc{PC2}, los cuales fueron superiores a lo propuesto como objetivo en el Capítulo 1. Se debe analizar el impacto de la arquitectura \emph{SMT} en \textsc{PC2} ya que la diferencia en el factor de rendimiento contra \textsc{PC1} es de prácticamente 1 punto. En el caso de tamaño \textsc{T80x80} en la etapa de optimización serial la aplicación logró un factor de mejora de 1.5 en \textsc{PC2}, mayor al conseguido para el tamaño \textsc{T50x50} en la misma etapa, lo cual puede deducirse de la mayor cantidad de datos que consume en su versión original en disco la aplicación para el tamaño \textsc{T80x80}, que ahora son accedidos en memoria. Para la etapa de optimización paralela con tamaño \textsc{T80x80}, el factor de mejora conseguido es de 1.73. Este factor menor en la mejora de rendimiento con respecto a la aplicación con \textsc{T50x50} se debe al mayor impacto que tiene la subrutina \emph{solgauss} a medida que el tamaño de problema aumenta. 

Como se indicó previamente, al analizar el uso de discos, se trasladaron los datos desde el sistema de archivos, residente en disco, a la memoria RAM para un acceso mas rápido. Se observó que prácticamente se duplicó la utilización de memoria RAM, pasando de 255 MB como máximo en la versión original a 552 MB máximos en la versión optimizada serialmente y 516 MB máximos en la versión optimizada paralelamente, sin que esto representara un inconveniente en los equipos utilizados. En equipos con 1 GB de RAM el programa seguiría teniendo memoria suficiente para ejecutarse usando el tamaño \textsc{T50x50}, y en la actualidad es habitual contar con 2 GB o más de RAM. 
Al incrementar el tamaño del problema debe tenerse en cuenta la cantidad de RAM disponible, ya que para el tamaño \textsc{T80x80} se observó que la ocupación memoria se incrementa más, alcanzando un máximo de 1581 MB en la versión original, 3483 MB máximos en la versión optimizada serialmente y 3184 MB máximos en la versión optimizada paralelamente. Al aumentar el tamaño del problema debe tenerse en cuenta la cantidad de memoria RAM disponible para evitar demoras en la ejecución por comportamientos no deseados, tales como el intercambio a disco de páginas de memoria. 

Del trabajo de tesis se obtuvo que la modernización de una aplicación heredada es posible siguiendo un proceso de optimización adecuado, aún cuando no se tiene documentación adecuada de la programación de la misma. Se debe tener en cuenta si el tamaño del problema resuelto por la aplicación se incrementa y analizar como afecta los recursos del equipo donde se ejecuta, especialmente cuando se decide paralelizar alguna parte del código. Además se pudo observar que porciones del código que en un tamaño de problema menor no tienen un impacto significativo en el tiempo, al incrementar el tamaño se vuelven relevantes y candidatos a ser paralelizados, ya que el factor de mejora en el rendimiento se ve reducido con respecto a tamaños de problema menores.

\section{Trabajos Futuros}
En función del trabajo de tesis se identificaron algunos aspectos que permitirían extender el trabajo realizado. Estos aspectos se detallan a continuación:
\begin{itemize}
\item Analizar si al aumentar aún más el tamaño del problema, con perfilado de la aplicación original, los tiempos consumidos por las subrutinas siguen variando, y a partir de esto analizar si es necesario optimizar nuevas porciones de código o cambiar la paralelización utilizada, por ejemplo pasar a MPI. También utilizar herramientas de perfilado de aplicaciones paralelas con OpenMP, como \emph{ompp}.
\item Otra línea de trabajo es una recodificación de la aplicación para aprovechar mejoras en el lenguaje Fortran y otras bibliotecas existentes para la realización de los cálculos.
\item Paralelizar la subrutina \emph{solgauss}, analizando recodificar la subrutina o si se puede paralelizar en su estado original. Además analizar la ganancia en rendimiento en el tamaño de problema menor para evaluar si es o no despreciable, y en problemas de mayor tamaño verificar si se logra una mejora en el rendimiento.
\item Realizar la optimización utilizando conjuntamente OpenMP y la API MPI, y analizar la posibilidad de utilizar un cluster para la ejecución de la aplicación aprovechando la capacidad de cómputo de varios nodos.
\item Paralelizar otras partes de la subrutina \emph{estela}, las sumatorias de términos pares e impares o el cálculo de coeficientes, con construcciones paralelas de OpenMP no utilizadas en este trabajo de tesis, como REDUCTION.

\end{itemize}